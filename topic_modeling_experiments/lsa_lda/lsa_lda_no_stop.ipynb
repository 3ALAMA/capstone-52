{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/capstone-52/Pickled_from_mongo\n"
     ]
    }
   ],
   "source": [
    "cd ../../Pickled_from_mongo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_eg_gulf_1k_sample.p  combined_eg_gulf_200k_sample.p\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../Pickled_from_mongo/combined_eg_gulf_200k_sample.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192936, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['cleaned_geo','cleaned_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.set_index(['cleaned_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 192936 entries, 0 to 95683\n",
      "Data columns (total 3 columns):\n",
      "_id             192936 non-null object\n",
      "cleaned_text    192936 non-null object\n",
      "class           192936 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192936, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91124</th>\n",
       "      <td>5a2ce210204c9e0400cf24d6</td>\n",
       "      <td>هناك فين</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75081</th>\n",
       "      <td>5a2edb834be1040042c23313</td>\n",
       "      <td>شئ مؤسف أن تصل الأمور في الى هذا المنحدر ويصنفها أعضاء في الكونغرس الامريكي بأنها تبتلع المعونات والوضع السياسي والاقتص…</td>\n",
       "      <td>GULF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>5a2c7ae3204c9e0400cdd92c</td>\n",
       "      <td>بس أنا بجيب ورد وشوكولا في الوقت المناسب برده )</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94045</th>\n",
       "      <td>5a2dd94e204c9e0400cf303f</td>\n",
       "      <td>عايزة فستان فرحي اللي مش هفرحه ده يبقى لونه أسود مثلاً</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67129</th>\n",
       "      <td>5a2cbe6b204c9e0400cec71b</td>\n",
       "      <td>يا دينى</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93442</th>\n",
       "      <td>5a2dd94e204c9e0400cf2de4</td>\n",
       "      <td>نحن بقع من العتم لولا نور الله فينا</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31064</th>\n",
       "      <td>5a2e2e1a4be1040042c18722</td>\n",
       "      <td>ادرس</td>\n",
       "      <td>GULF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26649</th>\n",
       "      <td>5a2e1bca4be1040042c175e3</td>\n",
       "      <td>شهاب لانه الاسم فخم ورجولي اكثر</td>\n",
       "      <td>GULF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _id  \\\n",
       "91124  5a2ce210204c9e0400cf24d6   \n",
       "75081  5a2edb834be1040042c23313   \n",
       "6218   5a2c7ae3204c9e0400cdd92c   \n",
       "94045  5a2dd94e204c9e0400cf303f   \n",
       "67129  5a2cbe6b204c9e0400cec71b   \n",
       "93442  5a2dd94e204c9e0400cf2de4   \n",
       "31064  5a2e2e1a4be1040042c18722   \n",
       "26649  5a2e1bca4be1040042c175e3   \n",
       "\n",
       "                                                                                                                   cleaned_text  \\\n",
       "91124  هناك فين                                                                                                                   \n",
       "75081  شئ مؤسف أن تصل الأمور في الى هذا المنحدر ويصنفها أعضاء في الكونغرس الامريكي بأنها تبتلع المعونات والوضع السياسي والاقتص…   \n",
       "6218   بس أنا بجيب ورد وشوكولا في الوقت المناسب برده )                                                                            \n",
       "94045  عايزة فستان فرحي اللي مش هفرحه ده يبقى لونه أسود مثلاً                                                                     \n",
       "67129  يا دينى                                                                                                                    \n",
       "93442  نحن بقع من العتم لولا نور الله فينا                                                                                        \n",
       "31064  ادرس                                                                                                                       \n",
       "26649  شهاب لانه الاسم فخم ورجولي اكثر                                                                                            \n",
       "\n",
       "      class  \n",
       "91124  EG    \n",
       "75081  GULF  \n",
       "6218   EG    \n",
       "94045  EG    \n",
       "67129  EG    \n",
       "93442  EG    \n",
       "31064  GULF  \n",
       "26649  GULF  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark LSA with no stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode the Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['class_numerical'] = le.fit_transform(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.class_numerical.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Document Term Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix_sps = tfidf_vectorizer.fit_transform(df.cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<192936x223045 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1807963 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_term_matrix_sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_array = np.asarray(document_term_matrix_sps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_array[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(tfidf * tfidf.T).A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix_df = pd.DataFrame(document_term_matrix_sps.toarray(),\n",
    "                                       index=df.index,\n",
    "                                       columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df.cleaned_text, document_term_matrix_df], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute SVD of Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 2\n",
    "SVD = TruncatedSVD(n_components)\n",
    "component_names = [\"component_\"+str(i+1) for i in range(n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_matrix = SVD.fit_transform(document_term_matrix_sps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_matrix[:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SVD Matrix with Documents and Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_semantic_analysis = pd.DataFrame(svd_matrix,\n",
    "                                        index=df.index,\n",
    "                                        columns=component_names)\n",
    "latent_semantic_analysis['cleaned_text'] = df.cleaned_text\n",
    "latent_semantic_analysis['class'] = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_semantic_analysis.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_loadings = pd.DataFrame(SVD.components_,\n",
    "                                   index=component_names,\n",
    "                                   columns=tfidf_vectorizer.get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_loadings['abs_component_1'] = np.abs(vocabulary_loadings.component_1)\n",
    "vocabulary_loadings['abs_component_2'] = np.abs(vocabulary_loadings.component_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA_Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Top Terms for Each Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 Terms for Component 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_loadings.sort_values('abs_component_1',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 Terms for Component 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_loadings.sort_values('abs_component_2',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Top Two Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "pc_1 = latent_semantic_analysis['component_1'].values\n",
    "pc_2 = latent_semantic_analysis['component_2'].values\n",
    "\n",
    "plt.scatter(pc_1, pc_2, c=df['class_numerical'], cmap='rainbow')\n",
    "\n",
    "plt.xlabel('First PC')\n",
    "plt.ylabel('Second PC')\n",
    "plt.axvline(linewidth=0.5)\n",
    "plt.axhline(linewidth=0.5)\n",
    "plt.xlim(-.1,1)\n",
    "plt.ylim(-.5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "pc_1 = latent_semantic_analysis['component_1'].values\n",
    "pc_2 = latent_semantic_analysis['component_2'].values\n",
    "\n",
    "strings = df['cleaned_text'].values\n",
    "for i, (x, y) in enumerate(zip(pc_1, pc_2)): \n",
    "    plt.text(x,y,strings[i][:10])\n",
    "\n",
    "plt.scatter(pc_1, pc_2, c=df['class_numerical'], cmap='rainbow')\n",
    "\n",
    "plt.xlabel('First PC')\n",
    "plt.ylabel('Second PC')\n",
    "plt.axvline(linewidth=0.5)\n",
    "plt.axhline(linewidth=0.5)\n",
    "plt.xlim(-.1,1)\n",
    "plt.ylim(-.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "pc_1 = latent_semantic_analysis['component_1'].values\n",
    "pc_2 = latent_semantic_analysis['component_2'].values\n",
    "\n",
    "plt.scatter(pc_1, pc_2, c=df['class_numerical'], cmap='rainbow')\n",
    "\n",
    "plt.xlabel('First PC')\n",
    "plt.ylabel('Second PC')\n",
    "plt.axvline(linewidth=0.5)\n",
    "plt.axhline(linewidth=0.5)\n",
    "plt.xlim(-.01,.5)\n",
    "plt.ylim(-.3,.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_mask = latent_semantic_analysis['class'] == 'EG'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_semantic_analysis[eg_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gulf_mask = latent_semantic_analysis['class'] == 'GULF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_semantic_analysis[gulf_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_semantic_analysis[(latent_semantic_analysis['class'] == 'EG') \n",
    "                         & (latent_semantic_analysis.component_2 > .050)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_semantic_analysis[(latent_semantic_analysis['class'] == 'GULF') \n",
    "                         & (latent_semantic_analysis.component_2 > .50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try `50` SVD components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 50\n",
    "SVD = TruncatedSVD(n_components)\n",
    "component_names = [\"component_\"+str(i+1) for i in range(n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_matrix = SVD.fit_transform(document_term_matrix_sps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(SVD.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_explained_variance_eg_gulf = np.cumsum(SVD.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_explained_variance_eg_gulf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the cumulative sum of the explained variance ratio from the `50` SVD components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "X = np.arange(1,51)\n",
    "cumulative_explained_variance_eg_gulf = np.cumsum(SVD.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(X, cumulative_explained_variance_eg_gulf, '-o')\n",
    "plt.bar(X, SVD.explained_variance_ratio_, align='center', alpha=0.5)\n",
    "\n",
    "for i, j in zip(X, np.cumsum(SVD.explained_variance_ratio_)):\n",
    "    plt.annotate(str(j.round(2)), xy=(i+.1,j-.01))\n",
    "    \n",
    "plt.xlabel('SVD components')\n",
    "plt.ylabel('Explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(50), np.cumsum(SVD.explained_variance_ratio_), label='cumulative explained variance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Top Terms for Each Component 'topics'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expression = pd.DataFrame(SVD.components_,\n",
    "                                     index=component_names,\n",
    "                                     columns=tfidf_vectorizer.get_feature_names()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,11):\n",
    "    vocabulary_expression['abs_component_{}'.format(i)] = np.abs(vocabulary_expression['component_{}'.format(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_1'].sort_values(ascending=False).head(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_2'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_3'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_4'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_5'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_6'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_7'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_8'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_9'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expression['abs_component_10'].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the search term using the same vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sentences = [\n",
    "{\"sentence\": \"الثوره المصريه تحولت من ثورة شارع محدش يزعل\", \"class\" : \"EG\"},\n",
    "{\"sentence\": \"نفسي اكون زيك بعرف اطنشك أو اخليك اخر حاجة و بعد كده اضحك عليك بكلمتين و انت تصدق كل مرة عادي\", \"class\" : \"EG\"},\n",
    "{\"sentence\": \"بما أن أغلب اللي متابعني مش بقدر اوصلهم أغلب الوقت. . ف كل يوم هعمل تويته آخر اليوم اللي هيعمل لايك\", \"class\" : \"EG\"},\n",
    "{\"sentence\": \"مقاومتنا للأشياء طلعت بتقل مع الزمن، مبقيناش نناهد ف حاجة.. و مش عشان أحنا جامدين قوي. هو حيلنا بس\", \"class\" : \"EG\"},\n",
    "{\"sentence\": \"عارف ايه احلى حاجة حاصلة ليا انى منك وانت برضه بتجرى فيا انت اخر كل يوم باخدك ف حضنى وانت اول\", \"class\" : \"EG\"},\n",
    "{\"sentence\": \"القاضى اللى حكم على المعتقلين بالاعدام هو هو نفس القاضى اللى هيراقب الانتخابات\", \"class\" : \"EG\"},\n",
    "{\"sentence\": \"وفجأة تيجي سيرة حاجة في وسط الكلام تقلب عليك القديم والجديد وترسم في دماغك علامات استفهام مالهاش\", \"class\" : \"EG\"},\n",
    "{\"sentence\": \"السنة اللي فاتت الاعلام الانجليزي قال المفروض بيب يعرف انه في البريمييرليج لازم يتأقلم و يلعب كورتنا\", \"class\" : \"EG\"},\n",
    "{\"sentence\": \"حرب و قتال و ناس تموت و هذا الدلخ يقول سعيد و مثل أجواء كرة القدم \", \"class\" : \"GULF\"},\n",
    "{\"sentence\": \"من غباء الهلالي الدلخ اللي يفتخر بفوز فريقه من قيادة رئيس الحكام كلاتنبيرغ له سنه ماسنع الحكام السعوديين\", \"class\" : \"GULF\"},\n",
    "{\"sentence\": \"شفتوا هوشة شيعان وغالي لو هي بين الهلاليين كان شفتوا هاشتاق كبر راسهم المنسم وكان جاك هذا الدلخ \", \"class\" : \"GULF\"},\n",
    "{\"sentence\": \"ذويه ارفضوا لانه عيار جمبازي مافيه شي وبليس مايكسر اماعينه يامال لضعفه قطو بو سبعة ارواح \", \"class\" : \"GULF\"},\n",
    "{\"sentence\": \"صج ياجماعه في سوال محيرني ليش المتان مافيهم النفسيه عكس الضعاف تقول خاشوقه ومنفس\", \"class\" : \"GULF\"},\n",
    "{\"sentence\": \"لم نعاند التاريخ مسيو خاشوقه بل الواقع والعقلانية ابعدنا من التدمير والانفلات\", \"class\" : \"GULF\"},\n",
    "{\"sentence\": \"أي والله وعندي عنه ابو خاشوقة أسرار لا تشرف قد أقولها اذا لم يلجم لسانه عن سب وطني\", \"class\" : \"GULF\"},\n",
    "{\"sentence\": \"قبل ماتتكلمين يالطيبه افهمي السالفه ومنب ملزومه بسنابي اني اشرح كل شيء صارت بالتفصيل بس لانك قلق خل\", \"class\" : \"GULF\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sentences_df = pd.DataFrame(search_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sentences_df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sentences_df.sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms_encoded = tfidf_vectorizer.transform(search_sentences_df.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms_encoded_df = pd.DataFrame(search_terms_encoded.toarray(), \n",
    "                                       index=search_sentences_df.sentence, \n",
    "                                       columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms_encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a Random Search Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_term_df = search_terms_encoded_df.sample(3)\n",
    "random_search_term_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append the search term to the document term matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_term_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_with_search_term.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_with_search_term.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_term_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_with_search_term = document_term_matrix_df.append(random_search_term_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_term_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtm_with_search_term.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_with_search_term.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_df = pd.DataFrame(svd_matrix, \n",
    "                      index=dtm_with_search_term.index, \n",
    "                      columns=component_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_with_search_term[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the Vector for our Search Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term_svd_vector = svd_df.loc[random_search_term_df.index]\n",
    "search_term_svd_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cosine Similarity to Find the Most Similar Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_df['cosine_sim'] = cosine_similarity(svd_df, search_term_svd_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_df[['cosine_sim']].sort_values('cosine_sim', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svd_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5ef792bb3575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvd_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'svd_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "svd_array = np.asarray(svd_matrix, dtype='int64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(svd_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svd_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9f9cdc9f52c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtopic_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_word_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svd_array' is not defined"
     ]
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=3, n_iter=1000, random_state=1)\n",
    "\n",
    "model.fit(svd_array)\n",
    "\n",
    "topic_word = model.topic_word_\n",
    "n_top_words = 3\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
